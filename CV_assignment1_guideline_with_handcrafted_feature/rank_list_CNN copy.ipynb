{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f0e8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import pandas as pd\n",
    "import glob\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "def extract_sift_des(image):\n",
    "    sift = cv2.ORB_create()\n",
    "    kp, des = sift.detectAndCompute(image, None)\n",
    "    return des\n",
    "\n",
    "def read_bounding_box(path):\n",
    "    boundary_file = open(path, 'r')\n",
    "    boundary = boundary_file.readline().strip().split(' ')\n",
    "    boundary = [int(b) for b in boundary]\n",
    "    boundary_file.close()\n",
    "    return boundary\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(260),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b742f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\IV\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\IV\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.9_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python39\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=EfficientNet_B3_Weights.IMAGENET1K_V1`. You can also use `weights=EfficientNet_B3_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "5000it [33:55,  2.46it/s]\n"
     ]
    }
   ],
   "source": [
    "download_path='C:/Users/IV/Desktop/CityU' # change to your own download path\n",
    "path_query=download_path+'/query_4186'\n",
    "path_query_txt=download_path+'/query_txt_4186'\n",
    "\n",
    "# path_query_txt is the directory to the bounding box information of the instance(s) for the query images\n",
    "path_gallery=download_path+'/gallery_4186'\n",
    "\n",
    "name_query=glob.glob(path_query+'/*.jpg')\n",
    "num_query=len(name_query)\n",
    "name_gallery=glob.glob(path_gallery+'/*.jpg')\n",
    "num_gallery=len(name_gallery)\n",
    "\n",
    "model = models.efficientnet_b3(pretrained=True)\n",
    "feat_extractor = model.features #define the feature extractor\n",
    "layer1 = model.features[:-1]\n",
    "feat_extractor.eval()  #set the mode as evaluation\n",
    "\n",
    "record_all=np.zeros((num_query,len(name_gallery)))\n",
    "\n",
    "query_imgs_no = [x.split('\\\\')[-1] for x in glob.glob(path_query+'/*.jpg')]\n",
    "query_imgs_no = [x[:-4] for x in query_imgs_no]\n",
    "\n",
    "gallery_imgs_no = [x.split('\\\\')[-1] for x in glob.glob(path_gallery+'/*.jpg')]\n",
    "gallery_imgs_no = [x[:-4] for x in gallery_imgs_no]\n",
    "\n",
    "gallery_features = []\n",
    "gallery_des = []\n",
    "\n",
    "for i, gallery_img_no in tqdm(enumerate(gallery_imgs_no)):\n",
    "    per_gallery_name = path_gallery+'/'+str(gallery_img_no)+'.jpg'\n",
    "    per_gallery=cv2.imread(per_gallery_name)\n",
    "    \n",
    "    # Image pre-processing\n",
    "    per_gallery = cv2.cvtColor(per_gallery,cv2.COLOR_BGR2YUV)\n",
    "    per_gallery[:,:,0] = cv2.equalizeHist(per_gallery[:,:,0])\n",
    "    per_gallery = cv2.cvtColor(per_gallery,cv2.COLOR_YUV2BGR)\n",
    "    per_gallery = cv2.GaussianBlur(per_gallery,(3,3),0)\n",
    "    gallery_sift = extract_sift_des(per_gallery)\n",
    "    per_gallery = Image.fromarray(per_gallery)\n",
    "\n",
    "    # preprocess the input image\n",
    "    img_transform = transform(per_gallery) #normalize the input image and transform it to tensor.\n",
    "    img_transform = torch.unsqueeze(img_transform, 0)\n",
    "    \n",
    "    # feature extraction for per gallery\n",
    "    with torch.no_grad():\n",
    "        per_gallery_features = model(img_transform)\n",
    "\n",
    "    gallery_features.append(per_gallery_features)\n",
    "    gallery_des.append(gallery_sift)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7499900d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [00:04,  4.13it/s]\n"
     ]
    }
   ],
   "source": [
    "query_features = []\n",
    "query_des = []\n",
    "for i, query_img_no in tqdm(enumerate(query_imgs_no[0:20])):\n",
    "    per_query_name=path_query+'/'+str(query_img_no)+'.jpg'\n",
    "    per_query=cv2.imread(per_query_name)\n",
    "    \n",
    "    # read boundary from text file\n",
    "    queryfilename = path_query_txt+'/'+str(query_img_no)+'.txt'\n",
    "    \n",
    "    # crop the image\n",
    "    boundary = read_bounding_box(queryfilename)\n",
    "    x ,y, w, h = boundary\n",
    "    query_boundary = per_query[y:y+h, x:x+w]\n",
    "\n",
    "    # Image pre-processing\n",
    "    query_boundary=cv2.cvtColor(query_boundary,cv2.COLOR_BGR2YUV)\n",
    "    query_boundary[:,:,0] = cv2.equalizeHist(query_boundary[:,:,0])\n",
    "    query_boundary = cv2.cvtColor(query_boundary,cv2.COLOR_YUV2BGR)\n",
    "    query_boundary = cv2.GaussianBlur(query_boundary,(3,3),0)\n",
    "\n",
    "    query_des.append(extract_sift_des(query_boundary))\n",
    "    query_boundary = Image.fromarray(query_boundary)\n",
    "    query_transformed = transform(query_boundary) #normalize the input image and transform it to tensor.\n",
    "    query_transformed = torch.unsqueeze(query_transformed, 0) #Set batchsize as 1. You can enlarge the batchsize to accelerate.\n",
    "\n",
    "    with torch.no_grad():\n",
    "        query_features.append(model(query_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9aff974e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 0: 5000it [00:16, 310.77it/s]\n",
      "1it [00:24, 24.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 1258 is 24.155112504959106s\n",
      "For query image No. 1258, the top 10 ranked similar image No. are 2403 4937 3886 1025 3689 230 4383 2941 1835 4696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 1: 5000it [00:15, 325.12it/s]\n",
      "2it [00:47, 23.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 1656 is 23.20803213119507s\n",
      "For query image No. 1656, the top 10 ranked similar image No. are 2003 839 1227 934 3875 2490 1243 991 2602 4498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 2: 5000it [00:15, 313.92it/s]\n",
      "3it [01:11, 23.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 1709 is 23.704833507537842s\n",
      "For query image No. 1709, the top 10 ranked similar image No. are 2857 4227 4152 2726 4083 3464 4778 3098 4280 4748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 3: 5000it [00:11, 436.56it/s]\n",
      "4it [01:30, 21.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 2032 is 18.951592445373535s\n",
      "For query image No. 2032, the top 10 ranked similar image No. are 4489 4340 1025 4207 4383 1815 2247 3038 2861 3804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 4: 5000it [00:15, 328.62it/s]\n",
      "5it [01:52, 22.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 2040 is 22.6904239654541s\n",
      "For query image No. 2040, the top 10 ranked similar image No. are 2666 2458 2711 880 664 2887 3083 2435 1080 4129\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 5: 5000it [00:13, 371.96it/s]\n",
      "6it [02:14, 22.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 2176 is 22.174010276794434s\n",
      "For query image No. 2176, the top 10 ranked similar image No. are 4018 268 4616 1741 139 2573 900 751 1025 1698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 6: 5000it [00:16, 302.20it/s]\n",
      "7it [02:39, 22.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 2461 is 24.2318434715271s\n",
      "For query image No. 2461, the top 10 ranked similar image No. are 1450 1044 852 4778 3859 2980 4006 2686 4026 4414\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 7: 5000it [00:13, 358.23it/s]\n",
      "8it [03:00, 22.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 27 is 21.712758541107178s\n",
      "For query image No. 27, the top 10 ranked similar image No. are 4731 4216 2722 204 3575 3200 2931 994 552 4180\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 8: 5000it [00:14, 341.89it/s]\n",
      "9it [03:23, 22.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 2714 is 22.192869424819946s\n",
      "For query image No. 2714, the top 10 ranked similar image No. are 3268 5005 2061 1703 310 4256 596 556 3152 4882\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 9: 5000it [00:15, 321.25it/s]\n",
      "10it [03:46, 22.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 316 is 23.32641625404358s\n",
      "For query image No. 316, the top 10 ranked similar image No. are 3399 1411 2684 143 1211 1025 3113 1927 3856 355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 10: 5000it [00:15, 314.31it/s]\n",
      "11it [04:10, 23.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 35 is 24.254753828048706s\n",
      "For query image No. 35, the top 10 ranked similar image No. are 1192 3544 1860 86 4249 231 930 2082 1084 1238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 11: 5000it [00:19, 250.53it/s]\n",
      "12it [04:39, 24.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 3502 is 28.525781869888306s\n",
      "For query image No. 3502, the top 10 ranked similar image No. are 4010 1137 851 3581 892 306 3753 3763 2334 3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 12: 5000it [00:19, 257.72it/s]\n",
      "13it [05:07, 25.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 3557 is 28.236743450164795s\n",
      "For query image No. 3557, the top 10 ranked similar image No. are 4325 291 3166 2642 4978 2384 231 3481 1627 171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 13: 5000it [00:10, 455.37it/s]\n",
      "14it [05:26, 23.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 3833 is 19.1198673248291s\n",
      "For query image No. 3833, the top 10 ranked similar image No. are 1038 2704 3831 2862 4616 2525 1411 1144 4696 82\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 14: 5000it [00:10, 469.51it/s]\n",
      "15it [05:44, 22.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 3906 is 18.153833627700806s\n",
      "For query image No. 3906, the top 10 ranked similar image No. are 3856 143 4055 2862 1492 1144 2999 792 3283 3257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 15: 5000it [00:18, 270.92it/s]\n",
      "16it [06:11, 23.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 4354 is 26.48249888420105s\n",
      "For query image No. 4354, the top 10 ranked similar image No. are 2 1690 19 820 4787 1835 1023 4705 1478 613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 16: 5000it [00:18, 270.18it/s]\n",
      "17it [06:38, 24.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 4445 is 27.058921813964844s\n",
      "For query image No. 4445, the top 10 ranked similar image No. are 1276 204 2949 1503 59 4598 3087 2296 1164 424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 17: 5000it [00:17, 291.09it/s]\n",
      "18it [07:03, 24.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 4716 is 25.791189193725586s\n",
      "For query image No. 4716, the top 10 ranked similar image No. are 1215 2088 1137 3084 306 1815 518 367 4978 3581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 18: 5000it [00:17, 279.38it/s]\n",
      "19it [07:30, 25.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 4929 is 26.23075008392334s\n",
      "For query image No. 4929, the top 10 ranked similar image No. are 672 1025 3350 931 4072 2782 2704 110 4948 1273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 19: 5000it [00:10, 475.81it/s]\n",
      "20it [07:48, 23.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 776 is 18.500486850738525s\n",
      "For query image No. 776, the top 10 ranked similar image No. are 204 694 4918 1612 3846 3850 4431 1958 2936 2778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "for i, query_img_no in tqdm(enumerate(query_imgs_no[0:20])):\n",
    "    time_s = time.time()\n",
    "    dist_record=[]\n",
    "    gallery_imgs_no_desc=[]\n",
    "    # the iteration loop for gallery\n",
    "    for j, gallery_img_no in tqdm(enumerate(gallery_imgs_no), desc=f\"Processing query part {i}\"):\n",
    "        sim_score1 = cosine_similarity(query_features[i], gallery_features[j]) \n",
    "        sim_score2 = cosine_similarity(query_des[i], gallery_des[j])\n",
    "        sim_score = sim_score1*0.7 + sim_score2*0.3\n",
    "        dist_record.append(sim_score)\n",
    "        # print(sim_score)\n",
    "        # find the indexes with descending similarity order\n",
    "        \n",
    "    descend_index=sorted(range(len(dist_record)), key=lambda k: np.max(dist_record[k]),reverse=True)\n",
    "    # update the results for one query\n",
    "    for k in range(len(descend_index)):\n",
    "        gallery_imgs_no_desc.append(np.array(gallery_imgs_no)[descend_index[k]])\n",
    "    record_all[i,:]= gallery_imgs_no_desc\n",
    "    time_e = time.time()\n",
    "    print('retrieval time for query {} is {}s'.format(query_img_no, time_e-time_s))\n",
    "    query_idx = i\n",
    "    print(f'For query image No. {query_imgs_no[query_idx]}, the top 10 ranked similar image No. are {gallery_imgs_no_desc[0]} {gallery_imgs_no_desc[1]} {gallery_imgs_no_desc[2]} {gallery_imgs_no_desc[3]} {gallery_imgs_no_desc[4]} {gallery_imgs_no_desc[5]} {gallery_imgs_no_desc[6]} {gallery_imgs_no_desc[7]} {gallery_imgs_no_desc[8]} {gallery_imgs_no_desc[9] }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0fd3d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output file following the example\n",
    "f=open(r'./rank_list_CNN&SIFT.txt','w')\n",
    "for i in range(num_query):\n",
    "    f.write('Q'+str(i+1)+': ')\n",
    "    for j in range(len(name_gallery)):\n",
    "        f.write(str(np.int32(record_all[i,j]))+' ')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "837b4ffd63ad5f8bd5765fb566d5ddb5232b205bbcd69cfbb0e2de9f87d13d59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
