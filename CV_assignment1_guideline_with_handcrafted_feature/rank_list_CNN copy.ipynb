{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import pandas as pd\n",
    "import glob\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def extract_sift_des(image):\n",
    "    sift = cv2.ORB_create()\n",
    "    kp, des = sift.detectAndCompute(image, None)\n",
    "    return des\n",
    "\n",
    "def read_bounding_box(path):\n",
    "    boundary_file = open(path, 'r')\n",
    "    boundary = boundary_file.readline().strip().split(' ')\n",
    "    boundary = [int(b) for b in boundary]\n",
    "    boundary_file.close()\n",
    "    return boundary\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(260),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b742f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "download_path='C:/Users/IV/Desktop/CityU' \n",
    "path_query=download_path+'/query_4186'\n",
    "path_query_txt=download_path+'/query_txt_4186'\n",
    "\n",
    "path_gallery=download_path+'/gallery_4186'\n",
    "\n",
    "name_query=glob.glob(path_query+'/*.jpg')\n",
    "num_query=len(name_query)\n",
    "name_gallery=glob.glob(path_gallery+'/*.jpg')\n",
    "num_gallery=len(name_gallery)\n",
    "\n",
    "model = models.efficientnet_b3(pretrained=True)\n",
    "feat_extractor = model.features #define the feature extractor\n",
    "layer1 = model.features[:-1]\n",
    "feat_extractor.eval()  #set the mode as evaluation\n",
    "\n",
    "record_all=np.zeros((num_query,len(name_gallery)))\n",
    "\n",
    "query_imgs_no = [x.split('\\\\')[-1] for x in glob.glob(path_query+'/*.jpg')]\n",
    "query_imgs_no = [x[:-4] for x in query_imgs_no]\n",
    "\n",
    "gallery_imgs_no = [x.split('\\\\')[-1] for x in glob.glob(path_gallery+'/*.jpg')]\n",
    "gallery_imgs_no = [x[:-4] for x in gallery_imgs_no]\n",
    "\n",
    "gallery_features = []\n",
    "gallery_des = []\n",
    "\n",
    "for i, gallery_img_no in tqdm(enumerate(gallery_imgs_no)):\n",
    "    per_gallery_name = path_gallery+'/'+str(gallery_img_no)+'.jpg'\n",
    "    per_gallery=cv2.imread(per_gallery_name)\n",
    "    \n",
    "    # Image pre-processing\n",
    "    per_gallery = cv2.cvtColor(per_gallery,cv2.COLOR_BGR2YUV)\n",
    "    per_gallery[:,:,0] = cv2.equalizeHist(per_gallery[:,:,0])\n",
    "    per_gallery = cv2.cvtColor(per_gallery,cv2.COLOR_YUV2BGR)\n",
    "    per_gallery = cv2.GaussianBlur(per_gallery,(3,3),0)\n",
    "    gallery_sift = extract_sift_des(per_gallery)\n",
    "    per_gallery = Image.fromarray(per_gallery)\n",
    "\n",
    "    # preprocess the input image\n",
    "    img_transform = transform(per_gallery) #normalize the input image and transform it to tensor.\n",
    "    img_transform = torch.unsqueeze(img_transform, 0)\n",
    "    \n",
    "    # feature extraction for per gallery\n",
    "    with torch.no_grad():\n",
    "        per_gallery_features = model(img_transform)\n",
    "\n",
    "    gallery_features.append(per_gallery_features)\n",
    "    gallery_des.append(gallery_sift)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7499900d",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_features = []\n",
    "query_des = []\n",
    "for i, query_img_no in tqdm(enumerate(query_imgs_no[0:20])):\n",
    "    per_query_name=path_query+'/'+str(query_img_no)+'.jpg'\n",
    "    per_query=cv2.imread(per_query_name)\n",
    "    \n",
    "    # read boundary from text file\n",
    "    queryfilename = path_query_txt+'/'+str(query_img_no)+'.txt'\n",
    "    \n",
    "    # crop the image\n",
    "    boundary = read_bounding_box(queryfilename)\n",
    "    x ,y, w, h = boundary\n",
    "    query_boundary = per_query[y:y+h, x:x+w]\n",
    "\n",
    "    # Image pre-processing\n",
    "    query_boundary=cv2.cvtColor(query_boundary,cv2.COLOR_BGR2YUV)\n",
    "    query_boundary[:,:,0] = cv2.equalizeHist(query_boundary[:,:,0])\n",
    "    query_boundary = cv2.cvtColor(query_boundary,cv2.COLOR_YUV2BGR)\n",
    "    query_boundary = cv2.GaussianBlur(query_boundary,(3,3),0)\n",
    "\n",
    "    query_des.append(extract_sift_des(query_boundary))\n",
    "    query_boundary = Image.fromarray(query_boundary)\n",
    "    query_transformed = transform(query_boundary) #normalize the input image and transform it to tensor.\n",
    "    query_transformed = torch.unsqueeze(query_transformed, 0) \n",
    "\n",
    "    with torch.no_grad():\n",
    "        query_features.append(model(query_transformed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff974e",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "for i, query_img_no in tqdm(enumerate(query_imgs_no[0:20])):\n",
    "    time_s = time.time()\n",
    "    dist_record=[]\n",
    "    gallery_imgs_no_desc=[]\n",
    "    # the iteration loop for gallery\n",
    "    for j, gallery_img_no in tqdm(enumerate(gallery_imgs_no), desc=f\"Processing query part {i}\"):\n",
    "        sim_score1 = cosine_similarity(query_features[i], gallery_features[j]) \n",
    "        sim_score2 = cosine_similarity(query_des[i], gallery_des[j])\n",
    "        sim_score = sim_score1*0.8 + sim_score2*0.2\n",
    "        dist_record.append(sim_score)\n",
    "        \n",
    "        # find the indexes with descending similarity order\n",
    "        \n",
    "    descend_index=sorted(range(len(dist_record)), key=lambda k: np.max(dist_record[k]),reverse=True)\n",
    "    # update the results for one query\n",
    "    for k in range(len(descend_index)):\n",
    "        gallery_imgs_no_desc.append(np.array(gallery_imgs_no)[descend_index[k]])\n",
    "    record_all[i,:]= gallery_imgs_no_desc\n",
    "    time_e = time.time()\n",
    "    print('retrieval time for query {} is {}s'.format(query_img_no, time_e-time_s))\n",
    "    query_idx = i\n",
    "    print(f'For query image No. {query_imgs_no[query_idx]}, the top 10 ranked similar image No. are {gallery_imgs_no_desc[0]} {gallery_imgs_no_desc[1]} {gallery_imgs_no_desc[2]} {gallery_imgs_no_desc[3]} {gallery_imgs_no_desc[4]} {gallery_imgs_no_desc[5]} {gallery_imgs_no_desc[6]} {gallery_imgs_no_desc[7]} {gallery_imgs_no_desc[8]} {gallery_imgs_no_desc[9] }')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output file following the example\n",
    "f=open(r'./rank_list_CNN&SIFT.txt','w')\n",
    "for i in range(num_query):\n",
    "    f.write('Q'+str(i+1)+': ')\n",
    "    for j in range(len(name_gallery)):\n",
    "        f.write(str(np.int32(record_all[i,j]))+' ')\n",
    "    f.write('\\n')\n",
    "f.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "837b4ffd63ad5f8bd5765fb566d5ddb5232b205bbcd69cfbb0e2de9f87d13d59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
