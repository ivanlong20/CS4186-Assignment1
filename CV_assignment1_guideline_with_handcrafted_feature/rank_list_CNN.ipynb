{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f0e8ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import pandas as pd\n",
    "import glob\n",
    "import time \n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import imutils\n",
    "\n",
    "def pyramid(image, scale=1.5, minSize=(30, 30)):\n",
    "\tyield image\n",
    "\twhile True:\n",
    "\t\tw = int(image.shape[1] / scale)\n",
    "\t\timage = imutils.resize(image, width=w)\n",
    "\t\tif image.shape[0] < minSize[1] or image.shape[1] < minSize[0]:\n",
    "\t\t\tbreak\n",
    "\t\tyield image\n",
    "\t\t\n",
    "def sliding_window(image, stepSize, windowSize):\n",
    "\tfor y in range(0, image.shape[0], stepSize):\n",
    "\t\tfor x in range(0, image.shape[1], stepSize):\n",
    "\t\t\tyield (x, y, image[y:y + windowSize[1], x:x + windowSize[0]])\n",
    "\n",
    "def read_bounding_box(path):\n",
    "    boundary_file = open(path, 'r')\n",
    "    boundary = boundary_file.readline().strip().split(' ')\n",
    "    boundary = [int(b) for b in boundary]\n",
    "    boundary_file.close()\n",
    "    return boundary\n",
    "\n",
    "def img_preprocess(img):\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_BGR2YUV)\n",
    "    img[:,:,0] = cv2.equalizeHist(img[:,:,0])\n",
    "    img = cv2.cvtColor(img,cv2.COLOR_YUV2BGR)\n",
    "    img = cv2.GaussianBlur(img,(3,3),0)\n",
    "    return img\n",
    "\n",
    "def initialize(download_path):\n",
    "    path_query=download_path+'/query_4186'\n",
    "    path_query_txt=download_path+'/query_txt_4186'\n",
    "\n",
    "    path_gallery=download_path+'/gallery_4186'\n",
    "\n",
    "    name_query=glob.glob(path_query+'/*.jpg')\n",
    "    num_query=len(name_query)\n",
    "    name_gallery=glob.glob(path_gallery+'/*.jpg')\n",
    "    num_gallery=len(name_gallery)\n",
    "    record_all=np.zeros((num_query,len(name_gallery)))\n",
    "    query_imgs_no = [x.split('\\\\')[-1] for x in glob.glob(path_query+'/*.jpg')]\n",
    "    query_imgs_no = [x[:-4] for x in query_imgs_no]\n",
    "\n",
    "    gallery_imgs_no = [x.split('\\\\')[-1] for x in glob.glob(path_gallery+'/*.jpg')]\n",
    "    gallery_imgs_no = [x[:-4] for x in gallery_imgs_no]\n",
    "    return path_gallery, path_query, path_query_txt, gallery_imgs_no, query_imgs_no, record_all, num_query, num_gallery\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.AutoAugment(transforms.AutoAugmentPolicy.IMAGENET),\n",
    "    transforms.Resize(260),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b742f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='C:/Users/IV/Desktop/CityU'\n",
    "path_gallery, path_query, path_query_txt, gallery_imgs_no, query_imgs_no, record_all, num_query, num_gallery = initialize(path)\n",
    "\n",
    "model = models.efficientnet_b1(pretrained=True)\n",
    "feat_extractor = model.features #define the feature extractor\n",
    "layer1 = model.features[:-1]\n",
    "feat_extractor.eval()  #set the mode as evaluation\n",
    "\n",
    "gallery_features = [[] for i in range(num_gallery)]\n",
    "\n",
    "for i, gallery_img_no in tqdm(enumerate(gallery_imgs_no)):\n",
    "    per_gallery_name = path_gallery+'/'+str(gallery_img_no)+'.jpg'\n",
    "    per_gallery=cv2.imread(per_gallery_name)\n",
    "\n",
    "    # Image pre-processing\n",
    "    per_gallery = img_preprocess(per_gallery)\n",
    "    # Define the window size\n",
    "    winW, winH = (400, 400)\n",
    "\n",
    "    # loop over the image pyramid\n",
    "    for resized in pyramid(per_gallery, scale=1.5):\n",
    "        for (x, y, window) in sliding_window(resized, stepSize=100, windowSize=(winW, winH)):\n",
    "            if window.shape[0] != winH or window.shape[1] != winW:\n",
    "                continue\n",
    "            window = Image.fromarray(window)\n",
    "\n",
    "            # preprocess the input image\n",
    "            img_transform = transform(window) #normalize the input image and transform it to tensor.\n",
    "            img_transform = torch.unsqueeze(img_transform, 0)\n",
    "            \n",
    "            # feature extraction for per gallery\n",
    "            with torch.no_grad():\n",
    "                per_gallery_features = model(img_transform)\n",
    "\n",
    "            gallery_features[i].append(per_gallery_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aff974e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, query_img_no in tqdm(enumerate(query_imgs_no[0:20])):\n",
    "    score_record=[]\n",
    "    time_s = time.time()\n",
    "    per_query_name=path_query+'/'+str(query_img_no)+'.jpg'\n",
    "    per_query=cv2.imread(per_query_name)\n",
    "    gallery_imgs_no_desc=[]\n",
    "    \n",
    "    # read boundary from text file\n",
    "    queryfilename = path_query_txt+'/'+str(query_img_no)+'.txt'\n",
    "    boundary = read_bounding_box(queryfilename)\n",
    "    \n",
    "    # crop the image\n",
    "    x ,y, w, h = boundary\n",
    "    query_boundary = per_query[y:y+h, x:x+w]\n",
    "    \n",
    "    # Image pre-processing\n",
    "    query_boundary  = img_preprocess(query_boundary)\n",
    "\n",
    "    # convert to PIL image\n",
    "    query_boundary = Image.fromarray(query_boundary)\n",
    "   \n",
    "    # feature extraction for per gallery\n",
    "    img_transform = transform(query_boundary) #normalize the input image and transform it to tensor.\n",
    "    img_transform = torch.unsqueeze(img_transform, 0) \n",
    "\n",
    "     # feature extraction for per gallery\n",
    "    with torch.no_grad():\n",
    "        query_feature_1 = model(img_transform)\n",
    "\n",
    "    # the iteration loop for gallery\n",
    "    for j, gallery_img_no in tqdm(enumerate(gallery_imgs_no), desc=f\"Processing query part {i}\"):\n",
    "\n",
    "        sim_scores = []\n",
    "        for k in range(len(gallery_features[j])):\n",
    "            if gallery_features[j][k] is None:\n",
    "                continue\n",
    "            sim_score = cosine_similarity(query_feature_1, gallery_features[j][k]) \n",
    "            sim_scores.append(sim_score)\n",
    "\n",
    "        if len(sim_scores) == 0:\n",
    "            max_score = 0\n",
    "        else:\n",
    "            max_score = max(sim_scores)\n",
    "\n",
    "        score_record.append(max_score)\n",
    "        \n",
    "    # find the indexes with descending similarity order\n",
    "    descend_index=sorted(range(len(score_record)), key=lambda k: np.max(score_record[k]),reverse=True)\n",
    "    # update the results for one query\n",
    "    for k in range(len(descend_index)):\n",
    "        gallery_imgs_no_desc.append(np.array(gallery_imgs_no)[descend_index[k]])\n",
    "    record_all[i,:]= gallery_imgs_no_desc\n",
    "    time_e = time.time()\n",
    "    print('retrieval time for query {} is {}s'.format(query_img_no, time_e-time_s))\n",
    "    query_idx = i\n",
    "    print(f'For query image No. {query_imgs_no[query_idx]}, the top 10 ranked similar image No. are {gallery_imgs_no_desc[0]} {gallery_imgs_no_desc[1]} {gallery_imgs_no_desc[2]} {gallery_imgs_no_desc[3]} {gallery_imgs_no_desc[4]} {gallery_imgs_no_desc[5]} {gallery_imgs_no_desc[6]} {gallery_imgs_no_desc[7]} {gallery_imgs_no_desc[8]} {gallery_imgs_no_desc[9] }')\n",
    "    print(f'For query image No. {query_imgs_no[query_idx]}, the similarity scores are {score_record[descend_index[0]]} {score_record[descend_index[1]]} {score_record[descend_index[2]]} {score_record[descend_index[3]]} {score_record[descend_index[4]]} {score_record[descend_index[5]]} {score_record[descend_index[6]]} {score_record[descend_index[7]]} {score_record[descend_index[8]]} {score_record[descend_index[9]] }')\n",
    "\n",
    "    filename=path_query+'/'+str(query_imgs_no[query_idx])+'.jpg'\n",
    "    image = mpimg.imread(filename)\n",
    "    plt.imshow(image)\n",
    "    plt.show()\n",
    "    for x in range(10):\n",
    "        filename=path_gallery+'/'+str(gallery_imgs_no_desc[x])+'.jpg'\n",
    "        image = mpimg.imread(filename)\n",
    "        plt.imshow(image)\n",
    "        plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fd3d53f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output file following the example\n",
    "f=open(r'./rank_list_CNN.txt','w')\n",
    "for i in range(num_query):\n",
    "    f.write('Q'+str(i+1)+': ')\n",
    "    for j in range(num_gallery):\n",
    "        f.write(str(np.int32(record_all[i,j]))+' ')\n",
    "    f.write('\\n')\n",
    "f.close()\n",
    "\n",
    "for i in range(num_query):\n",
    "    print('Q'+str(i+1)+': ',end=\"\")\n",
    "    for j in range(10):\n",
    "        print(str(np.int32(record_all[i,j]))+' ',end=\"\")\n",
    "    print('')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "837b4ffd63ad5f8bd5765fb566d5ddb5232b205bbcd69cfbb0e2de9f87d13d59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
