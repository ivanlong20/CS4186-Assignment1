{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f22e4061",
   "metadata": {},
   "source": [
    "**Simple example for Asg1 with handcrafted feature**\n",
    "\n",
    "An example diagram for instance search.\n",
    "Please read the slide \"Information for Asg1\" first.\n",
    "\n",
    "In every bounding box file (the txt files), each line records the coordinates of one bounding box in format: x of top-left point, y of top-left point, width, height.\n",
    "\n",
    "The bounding box information is only provided for the query images.\n",
    "\n",
    "Notes: it's possible that there are more than one instances in a query image (see the annotation(s) in the corresponding txt file), you should find the most similar image rank list in the gallery by considering all the instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "2a23afb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import pandas as pd\n",
    "import glob\n",
    "import time \n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import threading\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51e5e91",
   "metadata": {},
   "source": [
    " Download the dataset from this linke [onedrive link](https://portland-my.sharepoint.com/:u:/g/personal/srwang3-c_my_cityu_edu_hk/EZ0BIZatMIJMoiCG4-uy6okBSlXLJD7TUyIDG1lbKUJ0eA?e=lbKz4a).\n",
    "And unzip the downloaded file into some path. \n",
    "> In this tutorial, the path is `/Users/txsing/datasets_4186`, please replace to your own accordingly.\n",
    "\n",
    "Initialize the necessary parameters, including paths, feature extractors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "61bae164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "download_path='D:/Users/KLIVANCHAN/Desktop/CityU' # change to your own download path\n",
    "path_query=download_path+'/query_4186'\n",
    "path_query_txt=download_path+'/query_txt_4186'\n",
    "\n",
    "# path_query_txt is the directory to the bounding box information of the instance(s) for the query images\n",
    "path_gallery=download_path+'/gallery_4186'\n",
    "\n",
    "name_query=glob.glob(path_query+'/*.jpg')\n",
    "num_query=len(name_query)\n",
    "name_gallery=glob.glob(path_gallery+'/*.jpg')\n",
    "num_gallery=len(name_gallery)\n",
    "\n",
    "sift = cv2.ORB_create()\n",
    "# bf = cv2.BFMatcher()\n",
    "\n",
    "FLANN_INDEX_KDTREE = 1\n",
    "index_params = dict(algorithm = FLANN_INDEX_KDTREE, trees = 5)\n",
    "# search_params = dict(checks=50)\n",
    "flann = cv2.FlannBasedMatcher(index_params,{})\n",
    "\n",
    "record_all=np.zeros((num_query,len(name_gallery)))\n",
    "\n",
    "query_imgs_no = [x.split('\\\\')[-1] for x in glob.glob(path_query+'/*.jpg')]\n",
    "query_imgs_no = [x[:-4] for x in query_imgs_no]\n",
    "\n",
    "gallery_imgs_no = [x.split('\\\\')[-1] for x in glob.glob(path_gallery+'/*.jpg')]\n",
    "gallery_imgs_no = [x[:-4] for x in gallery_imgs_no]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33233d03",
   "metadata": {},
   "source": [
    "Process\n",
    "\n",
    "Feature extraction -> calculate distance -> compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "c2968b28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 0: 5000it [02:34, 32.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "retrieval time for query 1258 is 158.28146815299988s\n",
      "For query image No. 1258, the top ranked similar image No. is 2403.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing query part 1: 2511it [01:20, 31.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\1\\ipykernel_17984\\502168853.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[1;31m# feature extraction for per gallery\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m         \u001b[0mper_gallery_kp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mper_gallery_des\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msift\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetectAndCompute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mper_gallery\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[1;31m# use part of the features to make the calculation feasible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def instance_search(num):\n",
    "    for i, query_img_no in enumerate(query_imgs_no[num]):\n",
    "    \n",
    "    time_s = time.time()\n",
    "    dist_record=[]\n",
    "    per_query_name=path_query+'/'+str(query_img_no)+'.jpg'\n",
    "    per_query=cv2.imread(per_query_name)\n",
    "    gallery_imgs_no_desc=[]\n",
    "    \n",
    "    # read boundary from text file\n",
    "    queryfilename = path_query_txt+'/'+str(query_img_no)+'.txt'\n",
    "    boundary_file = open(queryfilename, 'r')\n",
    "    boundary = boundary_file.readline().strip().split(' ')\n",
    "    boundary = [int(b) for b in boundary]\n",
    "    boundary_file.close()\n",
    "    \n",
    "    # crop the image\n",
    "    x ,y, w, h = boundary\n",
    "    query_boundary = per_query[y:y+h, x:x+w]\n",
    "    \n",
    "    # feature extraction for per query\n",
    "    # the bounding box information is not considered\n",
    "    # quite naive, just an example\n",
    "    per_query_kp, per_query_des = sift.detectAndCompute(query_boundary,None)\n",
    "    \n",
    "    # the iteration loop for gallery\n",
    "    for j, gallery_img_no in tqdm(enumerate(gallery_imgs_no), desc=f\"Processing query part {i}\"):\n",
    "        per_gallery_name = path_gallery+'/'+str(gallery_img_no)+'.jpg'\n",
    "        per_gallery=cv2.imread(per_gallery_name)\n",
    "        \n",
    "        # feature extraction for per gallery\n",
    "        per_gallery_kp, per_gallery_des = sift.detectAndCompute(per_gallery,None)\n",
    "        \n",
    "        # use part of the features to make the calculation feasible\n",
    "        # quite naive, just an example\n",
    "#         matches = bf.knnMatch(np.asarray(per_query_des,np.float32),np.asarray(per_gallery_des,np.float32),k=2)\n",
    "        matches = flann.knnMatch(per_query_des.astype(np.float32),per_gallery_des.astype(np.float32),k=2)\n",
    "    \n",
    "        # Compute similarity score for each match\n",
    "        sim_scores = []\n",
    "        for match in matches:\n",
    "            if len(match) == 2:\n",
    "                (m,n) = match\n",
    "                query_desc = per_query_des[m.queryIdx]\n",
    "                gallery_desc = per_gallery_des[m.trainIdx]\n",
    "                sim_score = np.sum((np.double(query_desc)-np.double(gallery_desc))**2)/np.prod(np.shape(query_desc))\n",
    "                if np.isnan(sim_score):  # Check if similarity score is NaN\n",
    "                    continue\n",
    "                sim_scores.append(sim_score)\n",
    "\n",
    "        # Compute average similarity score for all matches\n",
    "        avg_sim_score = np.mean(sim_scores)\n",
    "        dist_record.append(avg_sim_score)\n",
    "#         cv2.imshow('result',per_result_img)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "    # find the indexes with descending similarity order\n",
    "    ascend_index=sorted(range(len(dist_record)), key=lambda k: dist_record[k])\n",
    "    # update the results for one query\n",
    "    for k in range(len(ascend_index)):\n",
    "        gallery_imgs_no_desc.append(np.array(gallery_imgs_no)[ascend_index[k]])\n",
    "    record_all[i,:]= gallery_imgs_no_desc\n",
    "    time_e = time.time()\n",
    "    sorted(dist_record)\n",
    "    print('retrieval time for query {} is {}s'.format(query_img_no, time_e-time_s))\n",
    "    query_idx = i\n",
    "    print(f'For query image No. {query_imgs_no[query_idx]}, the top ranked similar image No. is {gallery_imgs_no_desc[0]}.')\n",
    "    \n",
    " \n",
    " \n",
    "if __name__ ==\"__main__\":\n",
    "    # creating thread\n",
    "    threadList = [\"Thread-1\", \"Thread-2\", \"Thread-3\"]\n",
    "    threadID = 1\n",
    "    for tName in threadList:\n",
    "       thread = threading.Thread(target=instance_search, args=(i,))\n",
    "       thread.start()\n",
    "       threads.append(thread)\n",
    "       threadID += 1\n",
    "\n",
    "    for t in threads:\n",
    "        t.join()\n",
    "    print(\"Done!\")\n",
    "\n",
    "\n",
    "\n",
    "# the iteration loop for query \n",
    "# iteration times is 2 here, only for the demonstration\n",
    "for i, query_img_no in enumerate(query_imgs_no[0:20]):\n",
    "    \n",
    "    time_s = time.time()\n",
    "    dist_record=[]\n",
    "    per_query_name=path_query+'/'+str(query_img_no)+'.jpg'\n",
    "    per_query=cv2.imread(per_query_name)\n",
    "    gallery_imgs_no_desc=[]\n",
    "    \n",
    "    # read boundary from text file\n",
    "    queryfilename = path_query_txt+'/'+str(query_img_no)+'.txt'\n",
    "    boundary_file = open(queryfilename, 'r')\n",
    "    boundary = boundary_file.readline().strip().split(' ')\n",
    "    boundary = [int(b) for b in boundary]\n",
    "    boundary_file.close()\n",
    "    \n",
    "    # crop the image\n",
    "    x ,y, w, h = boundary\n",
    "    query_boundary = per_query[y:y+h, x:x+w]\n",
    "    \n",
    "    # feature extraction for per query\n",
    "    # the bounding box information is not considered\n",
    "    # quite naive, just an example\n",
    "    per_query_kp, per_query_des = sift.detectAndCompute(query_boundary,None)\n",
    "    \n",
    "    # the iteration loop for gallery\n",
    "    for j, gallery_img_no in tqdm(enumerate(gallery_imgs_no), desc=f\"Processing query part {i}\"):\n",
    "        per_gallery_name = path_gallery+'/'+str(gallery_img_no)+'.jpg'\n",
    "        per_gallery=cv2.imread(per_gallery_name)\n",
    "        \n",
    "        # feature extraction for per gallery\n",
    "        per_gallery_kp, per_gallery_des = sift.detectAndCompute(per_gallery,None)\n",
    "        \n",
    "        # use part of the features to make the calculation feasible\n",
    "        # quite naive, just an example\n",
    "#         matches = bf.knnMatch(np.asarray(per_query_des,np.float32),np.asarray(per_gallery_des,np.float32),k=2)\n",
    "        matches = flann.knnMatch(per_query_des.astype(np.float32),per_gallery_des.astype(np.float32),k=2)\n",
    "    \n",
    "        # Compute similarity score for each match\n",
    "        sim_scores = []\n",
    "        for match in matches:\n",
    "            if len(match) == 2:\n",
    "                (m,n) = match\n",
    "                query_desc = per_query_des[m.queryIdx]\n",
    "                gallery_desc = per_gallery_des[m.trainIdx]\n",
    "                sim_score = np.sum((np.double(query_desc)-np.double(gallery_desc))**2)/np.prod(np.shape(query_desc))\n",
    "                if np.isnan(sim_score):  # Check if similarity score is NaN\n",
    "                    continue\n",
    "                sim_scores.append(sim_score)\n",
    "\n",
    "        # Compute average similarity score for all matches\n",
    "        avg_sim_score = np.mean(sim_scores)\n",
    "        dist_record.append(avg_sim_score)\n",
    "#         cv2.imshow('result',per_result_img)\n",
    "#         cv2.waitKey(0)\n",
    "#         cv2.destroyAllWindows()\n",
    "\n",
    "    # find the indexes with descending similarity order\n",
    "    ascend_index=sorted(range(len(dist_record)), key=lambda k: dist_record[k])\n",
    "    # update the results for one query\n",
    "    for k in range(len(ascend_index)):\n",
    "        gallery_imgs_no_desc.append(np.array(gallery_imgs_no)[ascend_index[k]])\n",
    "    record_all[i,:]= gallery_imgs_no_desc\n",
    "    time_e = time.time()\n",
    "    sorted(dist_record)\n",
    "    print('retrieval time for query {} is {}s'.format(query_img_no, time_e-time_s))\n",
    "    query_idx = i\n",
    "    print(f'For query image No. {query_imgs_no[query_idx]}, the top ranked similar image No. is {gallery_imgs_no_desc[0]}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9d3349",
   "metadata": {},
   "source": [
    "Output \n",
    "\n",
    "Save the rank list file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5c8170",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the output file following the example\n",
    "f=open(r'./rank_list.txt','w')\n",
    "for i in range(num_query):\n",
    "    f.write('Q'+str(i+1)+': ')\n",
    "    for j in range(len(name_gallery)):\n",
    "        f.write(str(np.int32(record_all[i,j]))+' ')\n",
    "    f.write('\\n')\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "837b4ffd63ad5f8bd5765fb566d5ddb5232b205bbcd69cfbb0e2de9f87d13d59"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
